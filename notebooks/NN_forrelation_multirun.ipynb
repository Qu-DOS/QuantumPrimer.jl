{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load data\n",
    "# data = np.load('../data/forr_rand_fns_n4_change_basis.npz')\n",
    "# data = np.load('../data/forr_rand_fns_n6_change_basis.npz')\n",
    "data = np.load('../data/forr_rand_fns_n8_change_basis.npz')\n",
    "\n",
    "N = data['forr_f'].shape[2]\n",
    "\n",
    "# Load indices for training set samples\n",
    "df = pd.read_csv('../data/tr_inds.csv', header=None)\n",
    "data_idx = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv2D, MaxPooling2D\n",
    "from tensorflow import keras as tfk\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"\n",
    "    Calculates the Euclidean distance between two vectors.\n",
    "\n",
    "    Args:\n",
    "        vects: A tuple of two vectors (x, y).\n",
    "\n",
    "    Returns:\n",
    "        The Euclidean distance between the two vectors.\n",
    "    \"\"\"\n",
    "    x, y = vects\n",
    "    return tfk.backend.sqrt(tfk.backend.maximum(tfk.backend.sum(tfk.backend.square(x - y), axis=1, keepdims=True), tfk.backend.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    \"\"\"\n",
    "    Calculates the output shape of the Euclidean distance layer.\n",
    "\n",
    "    Parameters:\n",
    "    shapes (tuple): A tuple containing the shapes of the input tensors.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple representing the output shape of the Euclidean distance layer.\n",
    "        The first dimension is the batch size, and the second dimension is 1.\n",
    "    \"\"\"\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    \"\"\"\n",
    "    Creates a base network for a neural network model.\n",
    "\n",
    "    Parameters:\n",
    "    input_shape (tuple): The shape of the input data.\n",
    "\n",
    "    Returns:\n",
    "    keras.Model: The base network model.\n",
    "    \"\"\"\n",
    "    input = Input(shape=input_shape)\n",
    "    # x = Conv2D(32, (3, 3), activation='relu')(input)\n",
    "    # x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    # x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(128, activation='relu')(x) # use activation='sigmoid' if gradient-based optimization gives problems\n",
    "    # x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    # x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "# Create the base network\n",
    "base_network = create_base_network((N,))\n",
    "\n",
    "# Create the left input and point to the base network\n",
    "input_a = Input(shape=(N,))\n",
    "vect_output_a = base_network(input_a)\n",
    "\n",
    "# Create the right input and point to the base network\n",
    "input_b = Input(shape=(N,))\n",
    "vect_output_b = base_network(input_b)\n",
    "\n",
    "# Measure the similarity of the two vector outputs\n",
    "output = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([vect_output_a, vect_output_b])\n",
    "\n",
    "# Specify the inputs and output of the model\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Save the weights of the model for easier resetting\n",
    "model.save_weights('model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### New sample: 1 #####\n",
      "----------------  Sample: 1 | Average: 1  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.5000 - loss: 5.4662 - val_accuracy: 0.5000 - val_loss: 7.0048\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.5000 - loss: 1.2702 - val_accuracy: 0.5000 - val_loss: 6.5816\n",
      "----------------  Sample: 1 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.5000 - loss: 5.1787 - val_accuracy: 0.5000 - val_loss: 6.1490\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.5000 - loss: 2.2165 - val_accuracy: 0.5000 - val_loss: 5.7518\n",
      "----------------  Sample: 1 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - accuracy: 0.5000 - loss: 5.8675 - val_accuracy: 0.5000 - val_loss: 5.2448\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.5000 - loss: 3.5660 - val_accuracy: 0.5000 - val_loss: 4.7881\n",
      "----------------  Sample: 1 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.5000 - loss: 5.0973 - val_accuracy: 0.5000 - val_loss: 4.3327\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.5000 - loss: 2.9284 - val_accuracy: 0.5000 - val_loss: 3.9567\n",
      "----------------  Sample: 1 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - accuracy: 0.5000 - loss: 4.5393 - val_accuracy: 0.5000 - val_loss: 3.5835\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.5000 - loss: 2.9733 - val_accuracy: 0.5000 - val_loss: 3.2563\n",
      "----------------  Sample: 1 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716ms/step - accuracy: 0.5000 - loss: 2.1803 - val_accuracy: 0.5000 - val_loss: 2.9682\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.5000 - loss: 1.5564 - val_accuracy: 0.5000 - val_loss: 2.7258\n",
      "----------------  Sample: 1 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - accuracy: 0.5000 - loss: 1.7339 - val_accuracy: 0.5000 - val_loss: 2.5195\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.5000 - loss: 1.2552 - val_accuracy: 0.5000 - val_loss: 2.3388\n",
      "----------------  Sample: 1 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.5000 - loss: 3.3201 - val_accuracy: 0.5000 - val_loss: 2.1320\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.5000 - loss: 2.1846 - val_accuracy: 0.5000 - val_loss: 1.9438\n",
      "----------------  Sample: 1 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step - accuracy: 0.5000 - loss: 1.3678 - val_accuracy: 0.5000 - val_loss: 1.7858\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.5000 - loss: 1.0657 - val_accuracy: 0.5000 - val_loss: 1.6513\n",
      "----------------  Sample: 1 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step - accuracy: 0.5000 - loss: 2.4339 - val_accuracy: 0.5000 - val_loss: 1.5101\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.5000 - loss: 1.7831 - val_accuracy: 0.5000 - val_loss: 1.3808\n",
      "----------------  Sample: 1 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.5000 - loss: 1.1478 - val_accuracy: 0.5000 - val_loss: 1.2673\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5000 - loss: 0.8075 - val_accuracy: 0.5200 - val_loss: 1.1709\n",
      "----------------  Sample: 1 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.5000 - loss: 0.8454 - val_accuracy: 0.5400 - val_loss: 1.0833\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.5000 - loss: 0.6261 - val_accuracy: 0.5400 - val_loss: 1.0070\n",
      "----------------  Sample: 1 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.5000 - loss: 1.9799 - val_accuracy: 0.5400 - val_loss: 0.9234\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.5000 - loss: 1.4724 - val_accuracy: 0.5600 - val_loss: 0.8441\n",
      "----------------  Sample: 1 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.5000 - loss: 1.2258 - val_accuracy: 0.5800 - val_loss: 0.7655\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5000 - loss: 0.7982 - val_accuracy: 0.5800 - val_loss: 0.7004\n",
      "----------------  Sample: 1 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.5000 - loss: 0.3632 - val_accuracy: 0.5800 - val_loss: 0.6524\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.5000 - loss: 0.2309 - val_accuracy: 0.5800 - val_loss: 0.6162\n",
      "----------------  Sample: 1 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - accuracy: 0.5000 - loss: 0.3170 - val_accuracy: 0.6200 - val_loss: 0.5848\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.5000 - loss: 0.2761 - val_accuracy: 0.6400 - val_loss: 0.5560\n",
      "----------------  Sample: 1 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.5000 - loss: 0.3080 - val_accuracy: 0.6600 - val_loss: 0.5288\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.5000 - loss: 0.2632 - val_accuracy: 0.6600 - val_loss: 0.5039\n",
      "----------------  Sample: 1 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.5000 - loss: 1.2720 - val_accuracy: 0.7000 - val_loss: 0.4793\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5000 - loss: 0.9728 - val_accuracy: 0.7000 - val_loss: 0.4556\n",
      "----------------  Sample: 1 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.5000 - loss: 0.6632 - val_accuracy: 0.7000 - val_loss: 0.4278\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5000 - loss: 0.4896 - val_accuracy: 0.7000 - val_loss: 0.4013\n",
      "----------------  Sample: 1 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.5000 - loss: 0.5397 - val_accuracy: 0.7200 - val_loss: 0.3806\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.5000 - loss: 0.4530 - val_accuracy: 0.7200 - val_loss: 0.3640\n",
      "----------------  Sample: 1 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 0.0906 - val_accuracy: 0.7400 - val_loss: 0.3510\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0860 - val_accuracy: 0.7400 - val_loss: 0.3405\n",
      "----------------  Sample: 1 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.5000 - loss: 0.6130 - val_accuracy: 0.7600 - val_loss: 0.3302\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.5000 - loss: 0.5036 - val_accuracy: 0.7600 - val_loss: 0.3200\n",
      "----------------  Sample: 1 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.5000 - loss: 0.3904 - val_accuracy: 0.7800 - val_loss: 0.3091\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.5000 - loss: 0.3009 - val_accuracy: 0.7800 - val_loss: 0.2977\n",
      "----------------  Sample: 1 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.5000 - loss: 0.2820 - val_accuracy: 0.7600 - val_loss: 0.2861\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.5000 - loss: 0.2564 - val_accuracy: 0.7600 - val_loss: 0.2743\n",
      "----------------  Sample: 1 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0324 - val_accuracy: 0.7800 - val_loss: 0.2639\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 0.7800 - val_loss: 0.2545\n",
      "----------------  Sample: 1 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.5000 - loss: 0.2263 - val_accuracy: 0.8000 - val_loss: 0.2437\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.5000 - loss: 0.1821 - val_accuracy: 0.8200 - val_loss: 0.2329\n",
      "----------------  Sample: 1 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 0.2255 - val_accuracy: 0.8400 - val_loss: 0.2213\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 0.1644 - val_accuracy: 0.8400 - val_loss: 0.2108\n",
      "----------------  Sample: 1 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.5000 - loss: 0.2573 - val_accuracy: 0.8400 - val_loss: 0.2013\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5000 - loss: 0.2110 - val_accuracy: 0.8600 - val_loss: 0.1927\n",
      "----------------  Sample: 1 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 1.0000 - loss: 0.3616 - val_accuracy: 0.8600 - val_loss: 0.1862\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.2602 - val_accuracy: 0.8600 - val_loss: 0.1811\n",
      "----------------  Sample: 1 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 0.1163 - val_accuracy: 0.8800 - val_loss: 0.1769\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.1025 - val_accuracy: 0.8800 - val_loss: 0.1735\n",
      "----------------  Sample: 1 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 0.5000 - loss: 0.3088 - val_accuracy: 0.8600 - val_loss: 0.1703\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5000 - loss: 0.2580 - val_accuracy: 0.8600 - val_loss: 0.1675\n",
      "----------------  Sample: 1 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 0.1638 - val_accuracy: 0.8800 - val_loss: 0.1631\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.1149 - val_accuracy: 0.8800 - val_loss: 0.1585\n",
      "----------------  Sample: 1 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.5000 - loss: 0.1899 - val_accuracy: 0.8800 - val_loss: 0.1549\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.5000 - loss: 0.1578 - val_accuracy: 0.8800 - val_loss: 0.1519\n",
      "----------------  Sample: 1 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 1.0000 - loss: 0.0605 - val_accuracy: 0.9000 - val_loss: 0.1496\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0527 - val_accuracy: 0.9000 - val_loss: 0.1479\n",
      "----------------  Sample: 1 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 0.1846 - val_accuracy: 0.9000 - val_loss: 0.1447\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 0.1439 - val_accuracy: 0.9000 - val_loss: 0.1410\n",
      "----------------  Sample: 1 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.1093 - val_accuracy: 0.9000 - val_loss: 0.1383\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0854 - val_accuracy: 0.9000 - val_loss: 0.1361\n",
      "----------------  Sample: 1 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.5000 - loss: 0.1461 - val_accuracy: 0.8800 - val_loss: 0.1346\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.5000 - loss: 0.1294 - val_accuracy: 0.8800 - val_loss: 0.1336\n",
      "----------------  Sample: 1 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 1.0000 - loss: 0.0485 - val_accuracy: 0.8800 - val_loss: 0.1328\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0386 - val_accuracy: 0.8800 - val_loss: 0.1321\n",
      "----------------  Sample: 1 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.5000 - loss: 0.2655 - val_accuracy: 0.8400 - val_loss: 0.1315\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5000 - loss: 0.2270 - val_accuracy: 0.8400 - val_loss: 0.1311\n",
      "----------------  Sample: 1 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 0.1060 - val_accuracy: 0.8400 - val_loss: 0.1307\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.0933 - val_accuracy: 0.8400 - val_loss: 0.1303\n",
      "----------------  Sample: 1 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 1.0000 - loss: 0.0284 - val_accuracy: 0.8400 - val_loss: 0.1298\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 1.0000 - loss: 0.0256 - val_accuracy: 0.8600 - val_loss: 0.1293\n",
      "----------------  Sample: 1 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 0.0436 - val_accuracy: 0.8400 - val_loss: 0.1288\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0382 - val_accuracy: 0.8400 - val_loss: 0.1284\n",
      "----------------  Sample: 1 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 1.0000 - loss: 0.1174 - val_accuracy: 0.8400 - val_loss: 0.1272\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.1000 - val_accuracy: 0.8400 - val_loss: 0.1257\n",
      "----------------  Sample: 1 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - accuracy: 0.5000 - loss: 0.3310 - val_accuracy: 0.8600 - val_loss: 0.1219\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.5000 - loss: 0.2695 - val_accuracy: 0.8600 - val_loss: 0.1177\n",
      "----------------  Sample: 1 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.8600 - val_loss: 0.1150\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.8600 - val_loss: 0.1134\n",
      "----------------  Sample: 1 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.1178 - val_accuracy: 0.8600 - val_loss: 0.1116\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0992 - val_accuracy: 0.8600 - val_loss: 0.1098\n",
      "----------------  Sample: 1 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 1.0000 - loss: 0.0757 - val_accuracy: 0.8600 - val_loss: 0.1078\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0542 - val_accuracy: 0.8600 - val_loss: 0.1061\n",
      "----------------  Sample: 1 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 0.0383 - val_accuracy: 0.8600 - val_loss: 0.1050\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0346 - val_accuracy: 0.8600 - val_loss: 0.1045\n",
      "----------------  Sample: 1 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 1.0000 - loss: 0.0944 - val_accuracy: 0.8600 - val_loss: 0.1045\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0714 - val_accuracy: 0.8600 - val_loss: 0.1048\n",
      "----------------  Sample: 1 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0310 - val_accuracy: 0.8400 - val_loss: 0.1051\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 1.0000 - loss: 0.0286 - val_accuracy: 0.8400 - val_loss: 0.1055\n",
      "##### New sample: 2 #####\n",
      "----------------  Sample: 2 | Average: 1  ----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.5000 - loss: 9.5650 - val_accuracy: 0.5000 - val_loss: 7.1024\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5000 - loss: 6.3477 - val_accuracy: 0.5000 - val_loss: 6.4557\n",
      "----------------  Sample: 2 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.5000 - loss: 8.2632 - val_accuracy: 0.5000 - val_loss: 5.8295\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.5000 - loss: 5.4725 - val_accuracy: 0.5000 - val_loss: 5.2542\n",
      "----------------  Sample: 2 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.5000 - loss: 4.1881 - val_accuracy: 0.5000 - val_loss: 4.6619\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5000 - loss: 2.9036 - val_accuracy: 0.5000 - val_loss: 4.1356\n",
      "----------------  Sample: 2 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.5000 - loss: 3.6956 - val_accuracy: 0.5000 - val_loss: 3.6107\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.5000 - loss: 2.6529 - val_accuracy: 0.5000 - val_loss: 3.1496\n",
      "----------------  Sample: 2 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - accuracy: 0.5000 - loss: 3.5058 - val_accuracy: 0.5000 - val_loss: 2.7307\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5000 - loss: 2.2282 - val_accuracy: 0.5000 - val_loss: 2.3747\n",
      "----------------  Sample: 2 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.5000 - loss: 2.7618 - val_accuracy: 0.5000 - val_loss: 2.0611\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.5000 - loss: 1.8396 - val_accuracy: 0.5000 - val_loss: 1.7964\n",
      "----------------  Sample: 2 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.5000 - loss: 2.3111 - val_accuracy: 0.5000 - val_loss: 1.5747\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.5000 - loss: 1.6499 - val_accuracy: 0.5000 - val_loss: 1.3906\n",
      "----------------  Sample: 2 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - accuracy: 0.5000 - loss: 1.4704 - val_accuracy: 0.5200 - val_loss: 1.2204\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.5000 - loss: 1.1111 - val_accuracy: 0.5200 - val_loss: 1.0705\n",
      "----------------  Sample: 2 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - accuracy: 0.5000 - loss: 0.4315 - val_accuracy: 0.5200 - val_loss: 0.9517\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.5000 - loss: 0.2644 - val_accuracy: 0.5200 - val_loss: 0.8571\n",
      "----------------  Sample: 2 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.5000 - loss: 0.7820 - val_accuracy: 0.5400 - val_loss: 0.7692\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.5000 - loss: 0.5664 - val_accuracy: 0.5600 - val_loss: 0.6928\n",
      "----------------  Sample: 2 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step - accuracy: 0.5000 - loss: 1.5022 - val_accuracy: 0.5800 - val_loss: 0.6030\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.5000 - loss: 1.0953 - val_accuracy: 0.6000 - val_loss: 0.5189\n",
      "----------------  Sample: 2 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step - accuracy: 0.5000 - loss: 0.4626 - val_accuracy: 0.6000 - val_loss: 0.4571\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.5000 - loss: 0.3700 - val_accuracy: 0.6000 - val_loss: 0.4117\n",
      "----------------  Sample: 2 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - accuracy: 0.7500 - loss: 0.6722 - val_accuracy: 0.6400 - val_loss: 0.3763\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.7500 - loss: 0.5303 - val_accuracy: 0.6800 - val_loss: 0.3480\n",
      "----------------  Sample: 2 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.7500 - loss: 0.1746 - val_accuracy: 0.6800 - val_loss: 0.3256\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 0.1411 - val_accuracy: 0.7000 - val_loss: 0.3067\n",
      "----------------  Sample: 2 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.7500 - loss: 0.1771 - val_accuracy: 0.7200 - val_loss: 0.2880\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 0.1553 - val_accuracy: 0.7400 - val_loss: 0.2706\n",
      "----------------  Sample: 2 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.5000 - loss: 0.2303 - val_accuracy: 0.7400 - val_loss: 0.2540\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5000 - loss: 0.1967 - val_accuracy: 0.7800 - val_loss: 0.2395\n",
      "----------------  Sample: 2 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7500 - loss: 0.1400 - val_accuracy: 0.8000 - val_loss: 0.2269\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7500 - loss: 0.1226 - val_accuracy: 0.8000 - val_loss: 0.2159\n",
      "----------------  Sample: 2 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7500 - loss: 0.1891 - val_accuracy: 0.8000 - val_loss: 0.2066\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7500 - loss: 0.1754 - val_accuracy: 0.8000 - val_loss: 0.1989\n",
      "----------------  Sample: 2 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7500 - loss: 0.2249 - val_accuracy: 0.8000 - val_loss: 0.1917\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.1837 - val_accuracy: 0.8200 - val_loss: 0.1851\n",
      "----------------  Sample: 2 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7500 - loss: 0.1324 - val_accuracy: 0.8400 - val_loss: 0.1784\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7500 - loss: 0.1197 - val_accuracy: 0.8400 - val_loss: 0.1718\n",
      "----------------  Sample: 2 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.7500 - loss: 0.2143 - val_accuracy: 0.8400 - val_loss: 0.1658\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.7500 - loss: 0.1809 - val_accuracy: 0.8600 - val_loss: 0.1603\n",
      "----------------  Sample: 2 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step - accuracy: 1.0000 - loss: 0.0831 - val_accuracy: 0.8600 - val_loss: 0.1553\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 1.0000 - loss: 0.0671 - val_accuracy: 0.8600 - val_loss: 0.1508\n",
      "----------------  Sample: 2 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step - accuracy: 1.0000 - loss: 0.0988 - val_accuracy: 0.8600 - val_loss: 0.1466\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 0.0932 - val_accuracy: 0.9000 - val_loss: 0.1426\n",
      "----------------  Sample: 2 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570ms/step - accuracy: 1.0000 - loss: 0.0757 - val_accuracy: 0.8800 - val_loss: 0.1391\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0669 - val_accuracy: 0.9000 - val_loss: 0.1362\n",
      "----------------  Sample: 2 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - accuracy: 1.0000 - loss: 0.0622 - val_accuracy: 0.9000 - val_loss: 0.1336\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0555 - val_accuracy: 0.9000 - val_loss: 0.1313\n",
      "----------------  Sample: 2 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9000 - val_loss: 0.1294\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 0.0520 - val_accuracy: 0.9000 - val_loss: 0.1277\n",
      "----------------  Sample: 2 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 0.1243 - val_accuracy: 0.9000 - val_loss: 0.1256\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.1136 - val_accuracy: 0.8800 - val_loss: 0.1233\n",
      "----------------  Sample: 2 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 0.1239 - val_accuracy: 0.8800 - val_loss: 0.1216\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.1079 - val_accuracy: 0.8800 - val_loss: 0.1202\n",
      "----------------  Sample: 2 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 0.8800 - val_loss: 0.1191\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0183 - val_accuracy: 0.8800 - val_loss: 0.1183\n",
      "----------------  Sample: 2 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.7500 - loss: 0.1709 - val_accuracy: 0.8800 - val_loss: 0.1171\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.7500 - loss: 0.1586 - val_accuracy: 0.8800 - val_loss: 0.1157\n",
      "----------------  Sample: 2 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 1.0000 - loss: 0.0439 - val_accuracy: 0.8800 - val_loss: 0.1142\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0383 - val_accuracy: 0.8800 - val_loss: 0.1126\n",
      "----------------  Sample: 2 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 1.0000 - loss: 0.0880 - val_accuracy: 0.8800 - val_loss: 0.1108\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0774 - val_accuracy: 0.8800 - val_loss: 0.1089\n",
      "----------------  Sample: 2 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 1.0000 - loss: 0.0355 - val_accuracy: 0.8800 - val_loss: 0.1072\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.8800 - val_loss: 0.1059\n",
      "----------------  Sample: 2 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 1.0000 - loss: 0.1048 - val_accuracy: 0.9000 - val_loss: 0.1040\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0889 - val_accuracy: 0.9000 - val_loss: 0.1021\n",
      "----------------  Sample: 2 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 0.0806 - val_accuracy: 0.9000 - val_loss: 0.0998\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 0.0684 - val_accuracy: 0.9000 - val_loss: 0.0975\n",
      "----------------  Sample: 2 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.9000 - val_loss: 0.0959\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 0.9000 - val_loss: 0.0950\n",
      "----------------  Sample: 2 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 1.0000 - loss: 0.0406 - val_accuracy: 0.9000 - val_loss: 0.0943\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 0.0368 - val_accuracy: 0.9000 - val_loss: 0.0940\n",
      "----------------  Sample: 2 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.9000 - val_loss: 0.0938\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9000 - val_loss: 0.0938\n",
      "----------------  Sample: 2 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.0194 - val_accuracy: 0.9200 - val_loss: 0.0938\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.9200 - val_loss: 0.0939\n",
      "----------------  Sample: 2 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9400 - val_loss: 0.0939\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9400 - val_loss: 0.0940\n",
      "----------------  Sample: 2 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9400 - val_loss: 0.0942\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9400 - val_loss: 0.0943\n",
      "----------------  Sample: 2 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 0.9400 - val_loss: 0.0941\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0324 - val_accuracy: 0.9400 - val_loss: 0.0938\n",
      "----------------  Sample: 2 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 0.9400 - val_loss: 0.0935\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.9400 - val_loss: 0.0932\n",
      "----------------  Sample: 2 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 0.2489 - val_accuracy: 0.9400 - val_loss: 0.0898\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.2064 - val_accuracy: 0.9400 - val_loss: 0.0850\n",
      "----------------  Sample: 2 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 0.0314 - val_accuracy: 0.9400 - val_loss: 0.0817\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.9400 - val_loss: 0.0794\n",
      "----------------  Sample: 2 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 0.0255 - val_accuracy: 0.9400 - val_loss: 0.0779\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.9400 - val_loss: 0.0769\n",
      "----------------  Sample: 2 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 1.0000 - loss: 0.0517 - val_accuracy: 0.9400 - val_loss: 0.0760\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 0.0385 - val_accuracy: 0.9400 - val_loss: 0.0754\n",
      "----------------  Sample: 2 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.9400 - val_loss: 0.0751\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0232 - val_accuracy: 0.9400 - val_loss: 0.0751\n",
      "----------------  Sample: 2 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.7500 - loss: 0.1779 - val_accuracy: 0.9400 - val_loss: 0.0740\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.7500 - loss: 0.1570 - val_accuracy: 0.9400 - val_loss: 0.0722\n",
      "----------------  Sample: 2 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 1.0000 - loss: 0.0435 - val_accuracy: 0.9600 - val_loss: 0.0704\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 1.0000 - loss: 0.0376 - val_accuracy: 0.9600 - val_loss: 0.0686\n",
      "##### New sample: 3 #####\n",
      "----------------  Sample: 3 | Average: 1  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.5000 - loss: 5.7073 - val_accuracy: 0.5000 - val_loss: 7.3590\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.5000 - loss: 4.1418 - val_accuracy: 0.5000 - val_loss: 6.9311\n",
      "----------------  Sample: 3 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - accuracy: 0.5000 - loss: 7.5506 - val_accuracy: 0.5000 - val_loss: 6.1762\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.5000 - loss: 5.3301 - val_accuracy: 0.5000 - val_loss: 5.3757\n",
      "----------------  Sample: 3 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.5000 - loss: 4.3460 - val_accuracy: 0.5000 - val_loss: 4.6550\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.5000 - loss: 3.0399 - val_accuracy: 0.5000 - val_loss: 4.0507\n",
      "----------------  Sample: 3 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.5000 - loss: 4.6545 - val_accuracy: 0.5000 - val_loss: 3.4918\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.5000 - loss: 3.3383 - val_accuracy: 0.5000 - val_loss: 3.0048\n",
      "----------------  Sample: 3 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.5000 - loss: 2.7248 - val_accuracy: 0.5000 - val_loss: 2.6042\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5000 - loss: 1.9602 - val_accuracy: 0.5000 - val_loss: 2.2716\n",
      "----------------  Sample: 3 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 0.5000 - loss: 1.8035 - val_accuracy: 0.5000 - val_loss: 1.9852\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5000 - loss: 1.2689 - val_accuracy: 0.5000 - val_loss: 1.7465\n",
      "----------------  Sample: 3 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.5000 - loss: 2.5568 - val_accuracy: 0.5000 - val_loss: 1.5163\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5000 - loss: 1.8855 - val_accuracy: 0.5000 - val_loss: 1.3122\n",
      "----------------  Sample: 3 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.5000 - loss: 1.4366 - val_accuracy: 0.5000 - val_loss: 1.1219\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.5000 - loss: 1.0337 - val_accuracy: 0.5200 - val_loss: 0.9590\n",
      "----------------  Sample: 3 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.5000 - loss: 0.8292 - val_accuracy: 0.5400 - val_loss: 0.8296\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6667 - loss: 0.6172 - val_accuracy: 0.5600 - val_loss: 0.7257\n",
      "----------------  Sample: 3 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.5000 - loss: 0.4834 - val_accuracy: 0.5600 - val_loss: 0.6469\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5000 - loss: 0.3832 - val_accuracy: 0.5600 - val_loss: 0.5845\n",
      "----------------  Sample: 3 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.5000 - loss: 1.3717 - val_accuracy: 0.5800 - val_loss: 0.5206\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5000 - loss: 1.0164 - val_accuracy: 0.6000 - val_loss: 0.4604\n",
      "----------------  Sample: 3 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8333 - loss: 0.1099 - val_accuracy: 0.6000 - val_loss: 0.4137\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.8333 - loss: 0.0986 - val_accuracy: 0.6000 - val_loss: 0.3764\n",
      "----------------  Sample: 3 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.6667 - loss: 0.3801 - val_accuracy: 0.6400 - val_loss: 0.3413\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6667 - loss: 0.3118 - val_accuracy: 0.6800 - val_loss: 0.3094\n",
      "----------------  Sample: 3 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 0.1107 - val_accuracy: 0.7400 - val_loss: 0.2837\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 0.0996 - val_accuracy: 0.7400 - val_loss: 0.2632\n",
      "----------------  Sample: 3 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.6667 - loss: 0.2200 - val_accuracy: 0.7600 - val_loss: 0.2443\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6667 - loss: 0.1930 - val_accuracy: 0.7600 - val_loss: 0.2274\n",
      "----------------  Sample: 3 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.6667 - loss: 0.1680 - val_accuracy: 0.7600 - val_loss: 0.2137\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8333 - loss: 0.1496 - val_accuracy: 0.7800 - val_loss: 0.2024\n",
      "----------------  Sample: 3 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.8333 - loss: 0.1819 - val_accuracy: 0.8000 - val_loss: 0.1925\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.8333 - loss: 0.1695 - val_accuracy: 0.8200 - val_loss: 0.1839\n",
      "----------------  Sample: 3 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.8333 - loss: 0.1173 - val_accuracy: 0.8400 - val_loss: 0.1758\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8333 - loss: 0.1062 - val_accuracy: 0.8400 - val_loss: 0.1683\n",
      "----------------  Sample: 3 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.8333 - loss: 0.1531 - val_accuracy: 0.8400 - val_loss: 0.1613\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8333 - loss: 0.1372 - val_accuracy: 0.8400 - val_loss: 0.1545\n",
      "----------------  Sample: 3 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.8333 - loss: 0.1031 - val_accuracy: 0.8600 - val_loss: 0.1482\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0933 - val_accuracy: 0.8600 - val_loss: 0.1424\n",
      "----------------  Sample: 3 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - accuracy: 0.8333 - loss: 0.1006 - val_accuracy: 0.8600 - val_loss: 0.1373\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8333 - loss: 0.0906 - val_accuracy: 0.8800 - val_loss: 0.1329\n",
      "----------------  Sample: 3 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.8333 - loss: 0.0942 - val_accuracy: 0.9000 - val_loss: 0.1289\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8333 - loss: 0.0883 - val_accuracy: 0.9000 - val_loss: 0.1255\n",
      "----------------  Sample: 3 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - accuracy: 0.6667 - loss: 0.1027 - val_accuracy: 0.9000 - val_loss: 0.1223\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.8333 - loss: 0.0918 - val_accuracy: 0.9000 - val_loss: 0.1195\n",
      "----------------  Sample: 3 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - accuracy: 0.8333 - loss: 0.0798 - val_accuracy: 0.9000 - val_loss: 0.1168\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8333 - loss: 0.0745 - val_accuracy: 0.9000 - val_loss: 0.1143\n",
      "----------------  Sample: 3 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.6667 - loss: 0.1371 - val_accuracy: 0.9000 - val_loss: 0.1117\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6667 - loss: 0.1252 - val_accuracy: 0.9200 - val_loss: 0.1092\n",
      "----------------  Sample: 3 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8333 - loss: 0.1084 - val_accuracy: 0.9400 - val_loss: 0.1063\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8333 - loss: 0.1007 - val_accuracy: 0.9400 - val_loss: 0.1033\n",
      "----------------  Sample: 3 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8333 - loss: 0.1293 - val_accuracy: 0.9400 - val_loss: 0.0997\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8333 - loss: 0.1204 - val_accuracy: 0.9400 - val_loss: 0.0960\n",
      "----------------  Sample: 3 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 1.0000 - loss: 0.1030 - val_accuracy: 0.9400 - val_loss: 0.0928\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 0.0939 - val_accuracy: 0.9600 - val_loss: 0.0901\n",
      "----------------  Sample: 3 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.6667 - loss: 0.3479 - val_accuracy: 0.9800 - val_loss: 0.0848\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.6667 - loss: 0.3004 - val_accuracy: 1.0000 - val_loss: 0.0782\n",
      "----------------  Sample: 3 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 0.0322 - val_accuracy: 1.0000 - val_loss: 0.0730\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0299 - val_accuracy: 1.0000 - val_loss: 0.0689\n",
      "----------------  Sample: 3 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 1.0000 - loss: 0.0711 - val_accuracy: 0.9800 - val_loss: 0.0652\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.0661 - val_accuracy: 0.9800 - val_loss: 0.0620\n",
      "----------------  Sample: 3 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 1.0000 - loss: 0.0515 - val_accuracy: 0.9800 - val_loss: 0.0593\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0476 - val_accuracy: 0.9800 - val_loss: 0.0570\n",
      "----------------  Sample: 3 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step - accuracy: 1.0000 - loss: 0.0881 - val_accuracy: 0.9800 - val_loss: 0.0552\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 0.0817 - val_accuracy: 0.9800 - val_loss: 0.0536\n",
      "----------------  Sample: 3 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 1.0000 - loss: 0.0623 - val_accuracy: 0.9800 - val_loss: 0.0524\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0573 - val_accuracy: 0.9800 - val_loss: 0.0515\n",
      "----------------  Sample: 3 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 0.0321 - val_accuracy: 0.9800 - val_loss: 0.0509\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0302 - val_accuracy: 0.9800 - val_loss: 0.0504\n",
      "----------------  Sample: 3 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.8333 - loss: 0.0800 - val_accuracy: 1.0000 - val_loss: 0.0494\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0739 - val_accuracy: 1.0000 - val_loss: 0.0481\n",
      "----------------  Sample: 3 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 1.0000 - loss: 0.0429 - val_accuracy: 1.0000 - val_loss: 0.0470\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0405 - val_accuracy: 1.0000 - val_loss: 0.0459\n",
      "----------------  Sample: 3 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 1.0000 - loss: 0.0564 - val_accuracy: 1.0000 - val_loss: 0.0448\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0513 - val_accuracy: 1.0000 - val_loss: 0.0437\n",
      "----------------  Sample: 3 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step - accuracy: 1.0000 - loss: 0.0364 - val_accuracy: 1.0000 - val_loss: 0.0426\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0346 - val_accuracy: 1.0000 - val_loss: 0.0416\n",
      "----------------  Sample: 3 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0408\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0400\n",
      "----------------  Sample: 3 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 0.0596 - val_accuracy: 1.0000 - val_loss: 0.0388\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 0.0542 - val_accuracy: 1.0000 - val_loss: 0.0373\n",
      "----------------  Sample: 3 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0361\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0170 - val_accuracy: 1.0000 - val_loss: 0.0351\n",
      "----------------  Sample: 3 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0342\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.0335\n",
      "----------------  Sample: 3 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0329\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 1.0000 - val_loss: 0.0323\n",
      "----------------  Sample: 3 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 1.0000 - loss: 0.0479 - val_accuracy: 1.0000 - val_loss: 0.0314\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0440 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
      "----------------  Sample: 3 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 1.0000 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 0.0291\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 0.0281\n",
      "----------------  Sample: 3 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 0.0438 - val_accuracy: 1.0000 - val_loss: 0.0270\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0419 - val_accuracy: 1.0000 - val_loss: 0.0260\n",
      "----------------  Sample: 3 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0251\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
      "----------------  Sample: 3 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.0238\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0233\n",
      "----------------  Sample: 3 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
      "##### New sample: 4 #####\n",
      "----------------  Sample: 4 | Average: 1  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.5000 - loss: 6.5264 - val_accuracy: 0.5000 - val_loss: 7.1610\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.5000 - loss: 4.9469 - val_accuracy: 0.5000 - val_loss: 6.4779\n",
      "----------------  Sample: 4 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 0.5000 - loss: 6.3858 - val_accuracy: 0.5000 - val_loss: 5.6666\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.5000 - loss: 4.6483 - val_accuracy: 0.5000 - val_loss: 4.8797\n",
      "----------------  Sample: 4 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - accuracy: 0.5000 - loss: 4.0100 - val_accuracy: 0.5000 - val_loss: 4.1207\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.5000 - loss: 2.7156 - val_accuracy: 0.5000 - val_loss: 3.4849\n",
      "----------------  Sample: 4 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - accuracy: 0.5000 - loss: 3.6204 - val_accuracy: 0.5000 - val_loss: 2.9368\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.5000 - loss: 2.5342 - val_accuracy: 0.5000 - val_loss: 2.4857\n",
      "----------------  Sample: 4 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.5000 - loss: 2.5735 - val_accuracy: 0.5000 - val_loss: 2.0978\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.5000 - loss: 1.7843 - val_accuracy: 0.5000 - val_loss: 1.7761\n",
      "----------------  Sample: 4 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.5000 - loss: 2.3327 - val_accuracy: 0.5000 - val_loss: 1.4806\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.5000 - loss: 1.7068 - val_accuracy: 0.5000 - val_loss: 1.2269\n",
      "----------------  Sample: 4 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - accuracy: 0.5000 - loss: 0.9658 - val_accuracy: 0.5000 - val_loss: 1.0285\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.5000 - loss: 0.7055 - val_accuracy: 0.5400 - val_loss: 0.8734\n",
      "----------------  Sample: 4 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - accuracy: 0.5000 - loss: 0.8494 - val_accuracy: 0.5600 - val_loss: 0.7543\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.5000 - loss: 0.6386 - val_accuracy: 0.5800 - val_loss: 0.6609\n",
      "----------------  Sample: 4 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.5000 - loss: 0.7375 - val_accuracy: 0.6000 - val_loss: 0.5743\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.6250 - loss: 0.5817 - val_accuracy: 0.6200 - val_loss: 0.4973\n",
      "----------------  Sample: 4 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.5000 - loss: 0.6222 - val_accuracy: 0.6400 - val_loss: 0.4325\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.5000 - loss: 0.5134 - val_accuracy: 0.6400 - val_loss: 0.3781\n",
      "----------------  Sample: 4 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.6250 - loss: 0.5704 - val_accuracy: 0.7000 - val_loss: 0.3300\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.6250 - loss: 0.4472 - val_accuracy: 0.7200 - val_loss: 0.2897\n",
      "----------------  Sample: 4 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.6250 - loss: 0.3689 - val_accuracy: 0.7200 - val_loss: 0.2585\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6250 - loss: 0.3070 - val_accuracy: 0.7200 - val_loss: 0.2340\n",
      "----------------  Sample: 4 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - accuracy: 0.7500 - loss: 0.2673 - val_accuracy: 0.7200 - val_loss: 0.2140\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7500 - loss: 0.2229 - val_accuracy: 0.7600 - val_loss: 0.1975\n",
      "----------------  Sample: 4 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - accuracy: 0.7500 - loss: 0.3264 - val_accuracy: 0.8200 - val_loss: 0.1798\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.8750 - loss: 0.2770 - val_accuracy: 0.8400 - val_loss: 0.1628\n",
      "----------------  Sample: 4 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.8750 - loss: 0.1307 - val_accuracy: 0.8600 - val_loss: 0.1492\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8750 - loss: 0.1136 - val_accuracy: 0.8800 - val_loss: 0.1383\n",
      "----------------  Sample: 4 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.8750 - loss: 0.1213 - val_accuracy: 0.8800 - val_loss: 0.1296\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 0.1070 - val_accuracy: 0.8800 - val_loss: 0.1224\n",
      "----------------  Sample: 4 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step - accuracy: 1.0000 - loss: 0.1320 - val_accuracy: 0.8800 - val_loss: 0.1159\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.1147 - val_accuracy: 0.8800 - val_loss: 0.1101\n",
      "----------------  Sample: 4 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - accuracy: 0.8750 - loss: 0.1038 - val_accuracy: 0.9000 - val_loss: 0.1054\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 0.0936 - val_accuracy: 0.9000 - val_loss: 0.1012\n",
      "----------------  Sample: 4 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step - accuracy: 0.8750 - loss: 0.0967 - val_accuracy: 0.9000 - val_loss: 0.0974\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.8750 - loss: 0.0904 - val_accuracy: 0.9400 - val_loss: 0.0938\n",
      "----------------  Sample: 4 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 0.1006 - val_accuracy: 0.9400 - val_loss: 0.0909\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.0934 - val_accuracy: 0.9400 - val_loss: 0.0885\n",
      "----------------  Sample: 4 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.7500 - loss: 0.1178 - val_accuracy: 0.9800 - val_loss: 0.0863\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.1113 - val_accuracy: 0.9600 - val_loss: 0.0841\n",
      "----------------  Sample: 4 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 1.0000 - loss: 0.0818 - val_accuracy: 0.9600 - val_loss: 0.0819\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 0.0755 - val_accuracy: 0.9600 - val_loss: 0.0798\n",
      "----------------  Sample: 4 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step - accuracy: 0.8750 - loss: 0.0860 - val_accuracy: 0.9600 - val_loss: 0.0773\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8750 - loss: 0.0778 - val_accuracy: 0.9800 - val_loss: 0.0748\n",
      "----------------  Sample: 4 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 1.0000 - loss: 0.0633 - val_accuracy: 0.9600 - val_loss: 0.0727\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 0.0584 - val_accuracy: 0.9600 - val_loss: 0.0710\n",
      "----------------  Sample: 4 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8750 - loss: 0.0768 - val_accuracy: 0.9600 - val_loss: 0.0689\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.8750 - loss: 0.0731 - val_accuracy: 0.9600 - val_loss: 0.0667\n",
      "----------------  Sample: 4 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step - accuracy: 1.0000 - loss: 0.0705 - val_accuracy: 0.9800 - val_loss: 0.0648\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 1.0000 - loss: 0.0650 - val_accuracy: 0.9800 - val_loss: 0.0632\n",
      "----------------  Sample: 4 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 1.0000 - loss: 0.0344 - val_accuracy: 0.9800 - val_loss: 0.0616\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0311 - val_accuracy: 0.9800 - val_loss: 0.0600\n",
      "----------------  Sample: 4 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0849 - val_accuracy: 0.9800 - val_loss: 0.0584\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 0.0793 - val_accuracy: 0.9800 - val_loss: 0.0567\n",
      "----------------  Sample: 4 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - accuracy: 1.0000 - loss: 0.0515 - val_accuracy: 0.9800 - val_loss: 0.0551\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 0.0477 - val_accuracy: 0.9800 - val_loss: 0.0536\n",
      "----------------  Sample: 4 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8750 - loss: 0.1056 - val_accuracy: 0.9800 - val_loss: 0.0523\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.0983 - val_accuracy: 0.9800 - val_loss: 0.0511\n",
      "----------------  Sample: 4 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 0.0487 - val_accuracy: 0.9800 - val_loss: 0.0499\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0446 - val_accuracy: 0.9800 - val_loss: 0.0485\n",
      "----------------  Sample: 4 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - accuracy: 1.0000 - loss: 0.0308 - val_accuracy: 0.9800 - val_loss: 0.0473\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0297 - val_accuracy: 0.9800 - val_loss: 0.0462\n",
      "----------------  Sample: 4 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - accuracy: 1.0000 - loss: 0.0379 - val_accuracy: 0.9800 - val_loss: 0.0450\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 0.0344 - val_accuracy: 0.9800 - val_loss: 0.0437\n",
      "----------------  Sample: 4 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.9800 - val_loss: 0.0427\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.9800 - val_loss: 0.0418\n",
      "----------------  Sample: 4 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0537 - val_accuracy: 0.9800 - val_loss: 0.0406\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 0.0506 - val_accuracy: 0.9800 - val_loss: 0.0392\n",
      "----------------  Sample: 4 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 1.0000 - loss: 0.0376 - val_accuracy: 0.9800 - val_loss: 0.0380\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0349 - val_accuracy: 0.9800 - val_loss: 0.0370\n",
      "----------------  Sample: 4 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.9800 - val_loss: 0.0359\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.9800 - val_loss: 0.0349\n",
      "----------------  Sample: 4 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step - accuracy: 1.0000 - loss: 0.0392 - val_accuracy: 0.9800 - val_loss: 0.0340\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 0.0369 - val_accuracy: 0.9800 - val_loss: 0.0333\n",
      "----------------  Sample: 4 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.0293 - val_accuracy: 0.9800 - val_loss: 0.0326\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 0.0278 - val_accuracy: 0.9800 - val_loss: 0.0320\n",
      "----------------  Sample: 4 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9800 - val_loss: 0.0315\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9800 - val_loss: 0.0311\n",
      "----------------  Sample: 4 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9800 - val_loss: 0.0307\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9800 - val_loss: 0.0303\n",
      "----------------  Sample: 4 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.9800 - val_loss: 0.0301\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.9800 - val_loss: 0.0298\n",
      "----------------  Sample: 4 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.9800 - val_loss: 0.0296\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.9800 - val_loss: 0.0295\n",
      "----------------  Sample: 4 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.9800 - val_loss: 0.0293\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.9800 - val_loss: 0.0290\n",
      "----------------  Sample: 4 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 0.9800 - val_loss: 0.0288\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 0.9800 - val_loss: 0.0286\n",
      "----------------  Sample: 4 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.9800 - val_loss: 0.0284\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.9800 - val_loss: 0.0283\n",
      "----------------  Sample: 4 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 0.9800 - val_loss: 0.0281\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 0.9800 - val_loss: 0.0279\n",
      "----------------  Sample: 4 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9800 - val_loss: 0.0278\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.9800 - val_loss: 0.0276\n",
      "----------------  Sample: 4 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9800 - val_loss: 0.0275\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9800 - val_loss: 0.0273\n",
      "----------------  Sample: 4 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0435 - val_accuracy: 0.9800 - val_loss: 0.0266\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 0.0402 - val_accuracy: 0.9800 - val_loss: 0.0256\n",
      "##### New sample: 5 #####\n",
      "----------------  Sample: 5 | Average: 1  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 0.5000 - loss: 7.6612 - val_accuracy: 0.5000 - val_loss: 7.1126\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5000 - loss: 5.9347 - val_accuracy: 0.5000 - val_loss: 6.3439\n",
      "----------------  Sample: 5 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.5000 - loss: 8.0409 - val_accuracy: 0.5000 - val_loss: 5.4698\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.5000 - loss: 5.8620 - val_accuracy: 0.5000 - val_loss: 4.6383\n",
      "----------------  Sample: 5 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.5000 - loss: 4.9359 - val_accuracy: 0.5000 - val_loss: 3.8069\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.5000 - loss: 3.4705 - val_accuracy: 0.5000 - val_loss: 3.0872\n",
      "----------------  Sample: 5 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step - accuracy: 0.5000 - loss: 3.1971 - val_accuracy: 0.5000 - val_loss: 2.4851\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.5000 - loss: 2.1146 - val_accuracy: 0.5000 - val_loss: 2.0117\n",
      "----------------  Sample: 5 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459ms/step - accuracy: 0.5000 - loss: 1.7321 - val_accuracy: 0.5000 - val_loss: 1.6294\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.5000 - loss: 1.2504 - val_accuracy: 0.5000 - val_loss: 1.3276\n",
      "----------------  Sample: 5 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.5000 - loss: 1.1717 - val_accuracy: 0.5000 - val_loss: 1.0916\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.5000 - loss: 0.8428 - val_accuracy: 0.5000 - val_loss: 0.9110\n",
      "----------------  Sample: 5 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 0.5000 - loss: 0.6125 - val_accuracy: 0.5200 - val_loss: 0.7738\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.5000 - loss: 0.4331 - val_accuracy: 0.5600 - val_loss: 0.6697\n",
      "----------------  Sample: 5 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.5000 - loss: 0.8612 - val_accuracy: 0.5600 - val_loss: 0.5819\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.6000 - loss: 0.6836 - val_accuracy: 0.6000 - val_loss: 0.5071\n",
      "----------------  Sample: 5 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.6000 - loss: 0.6983 - val_accuracy: 0.6600 - val_loss: 0.4363\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.6000 - loss: 0.5533 - val_accuracy: 0.6800 - val_loss: 0.3723\n",
      "----------------  Sample: 5 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.9000 - loss: 0.1311 - val_accuracy: 0.7400 - val_loss: 0.3236\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 0.1223 - val_accuracy: 0.7400 - val_loss: 0.2861\n",
      "----------------  Sample: 5 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 0.6000 - loss: 0.4186 - val_accuracy: 0.7600 - val_loss: 0.2520\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.6000 - loss: 0.3513 - val_accuracy: 0.7600 - val_loss: 0.2217\n",
      "----------------  Sample: 5 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.7000 - loss: 0.3234 - val_accuracy: 0.7600 - val_loss: 0.1963\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.7000 - loss: 0.2656 - val_accuracy: 0.7800 - val_loss: 0.1757\n",
      "----------------  Sample: 5 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.8000 - loss: 0.1909 - val_accuracy: 0.7800 - val_loss: 0.1597\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.8000 - loss: 0.1559 - val_accuracy: 0.7800 - val_loss: 0.1469\n",
      "----------------  Sample: 5 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.7000 - loss: 0.1888 - val_accuracy: 0.8400 - val_loss: 0.1362\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.7000 - loss: 0.1672 - val_accuracy: 0.8400 - val_loss: 0.1274\n",
      "----------------  Sample: 5 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8000 - loss: 0.1171 - val_accuracy: 0.8600 - val_loss: 0.1194\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.8000 - loss: 0.1088 - val_accuracy: 0.9000 - val_loss: 0.1124\n",
      "----------------  Sample: 5 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 1.0000 - loss: 0.1658 - val_accuracy: 0.9000 - val_loss: 0.1059\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 0.1468 - val_accuracy: 0.9000 - val_loss: 0.1001\n",
      "----------------  Sample: 5 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - accuracy: 0.9000 - loss: 0.1026 - val_accuracy: 0.9000 - val_loss: 0.0947\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9000 - loss: 0.0932 - val_accuracy: 0.9400 - val_loss: 0.0900\n",
      "----------------  Sample: 5 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.9000 - loss: 0.1022 - val_accuracy: 0.9400 - val_loss: 0.0861\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.9000 - loss: 0.0928 - val_accuracy: 0.9400 - val_loss: 0.0830\n",
      "----------------  Sample: 5 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.9000 - loss: 0.1129 - val_accuracy: 0.9400 - val_loss: 0.0795\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9000 - loss: 0.1036 - val_accuracy: 0.9400 - val_loss: 0.0756\n",
      "----------------  Sample: 5 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 0.0466 - val_accuracy: 1.0000 - val_loss: 0.0723\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 0.0417 - val_accuracy: 1.0000 - val_loss: 0.0694\n",
      "----------------  Sample: 5 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - accuracy: 0.9000 - loss: 0.1386 - val_accuracy: 1.0000 - val_loss: 0.0663\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9000 - loss: 0.1326 - val_accuracy: 1.0000 - val_loss: 0.0630\n",
      "----------------  Sample: 5 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.9000 - loss: 0.0740 - val_accuracy: 0.9800 - val_loss: 0.0600\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9000 - loss: 0.0682 - val_accuracy: 0.9800 - val_loss: 0.0571\n",
      "----------------  Sample: 5 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.9000 - loss: 0.0741 - val_accuracy: 0.9800 - val_loss: 0.0544\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.9000 - loss: 0.0701 - val_accuracy: 1.0000 - val_loss: 0.0516\n",
      "----------------  Sample: 5 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.9000 - loss: 0.0902 - val_accuracy: 1.0000 - val_loss: 0.0491\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.9000 - loss: 0.0840 - val_accuracy: 1.0000 - val_loss: 0.0470\n",
      "----------------  Sample: 5 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 1.0000 - loss: 0.0416 - val_accuracy: 1.0000 - val_loss: 0.0451\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0372 - val_accuracy: 1.0000 - val_loss: 0.0434\n",
      "----------------  Sample: 5 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 1.0000 - loss: 0.1338 - val_accuracy: 1.0000 - val_loss: 0.0420\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 0.1222 - val_accuracy: 1.0000 - val_loss: 0.0408\n",
      "----------------  Sample: 5 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 0.0694 - val_accuracy: 1.0000 - val_loss: 0.0395\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.0637 - val_accuracy: 1.0000 - val_loss: 0.0381\n",
      "----------------  Sample: 5 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 1.0000 - loss: 0.0388 - val_accuracy: 1.0000 - val_loss: 0.0366\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 1.0000 - loss: 0.0369 - val_accuracy: 1.0000 - val_loss: 0.0351\n",
      "----------------  Sample: 5 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 0.0326 - val_accuracy: 1.0000 - val_loss: 0.0337\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 0.0324\n",
      "----------------  Sample: 5 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 0.0312\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 1.0000 - loss: 0.0329 - val_accuracy: 1.0000 - val_loss: 0.0301\n",
      "----------------  Sample: 5 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 1.0000 - loss: 0.0332 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0297 - val_accuracy: 1.0000 - val_loss: 0.0276\n",
      "----------------  Sample: 5 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 1.0000 - loss: 0.0339 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 0.0254\n",
      "----------------  Sample: 5 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0418 - val_accuracy: 1.0000 - val_loss: 0.0246\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0397 - val_accuracy: 1.0000 - val_loss: 0.0238\n",
      "----------------  Sample: 5 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0231\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0225\n",
      "----------------  Sample: 5 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 1.0000 - val_loss: 0.0218\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0212\n",
      "----------------  Sample: 5 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 0.0207\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0202\n",
      "----------------  Sample: 5 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 0.0256 - val_accuracy: 1.0000 - val_loss: 0.0198\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0195\n",
      "----------------  Sample: 5 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0190\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0184\n",
      "----------------  Sample: 5 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0179\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 0.0175\n",
      "----------------  Sample: 5 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 1.0000 - loss: 0.0274 - val_accuracy: 1.0000 - val_loss: 0.0171\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 1.0000 - val_loss: 0.0168\n",
      "----------------  Sample: 5 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0165\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 1.0000 - val_loss: 0.0162\n",
      "----------------  Sample: 5 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0159\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0157\n",
      "----------------  Sample: 5 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
      "----------------  Sample: 5 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 0.0149\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0147\n",
      "----------------  Sample: 5 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0186 - val_accuracy: 1.0000 - val_loss: 0.0144\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0142\n",
      "----------------  Sample: 5 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 1.0000 - val_loss: 0.0138\n",
      "----------------  Sample: 5 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0134\n",
      "----------------  Sample: 5 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0258 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
      "----------------  Sample: 5 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0129\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0126\n",
      "----------------  Sample: 5 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0124\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0121\n",
      "##### New sample: 6 #####\n",
      "----------------  Sample: 6 | Average: 1  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.5000 - loss: 8.3087 - val_accuracy: 0.5000 - val_loss: 7.0633\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.5000 - loss: 6.4686 - val_accuracy: 0.5000 - val_loss: 6.2133\n",
      "----------------  Sample: 6 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.5000 - loss: 6.6981 - val_accuracy: 0.5000 - val_loss: 5.2802\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.5000 - loss: 4.5036 - val_accuracy: 0.5000 - val_loss: 4.4375\n",
      "----------------  Sample: 6 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 0.5000 - loss: 5.2702 - val_accuracy: 0.5000 - val_loss: 3.5767\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.5000 - loss: 3.7115 - val_accuracy: 0.5000 - val_loss: 2.8355\n",
      "----------------  Sample: 6 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.5000 - loss: 3.2065 - val_accuracy: 0.5000 - val_loss: 2.2153\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.5000 - loss: 2.3217 - val_accuracy: 0.5000 - val_loss: 1.7309\n",
      "----------------  Sample: 6 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - accuracy: 0.5000 - loss: 2.3011 - val_accuracy: 0.5000 - val_loss: 1.3480\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - accuracy: 0.5000 - loss: 1.6771 - val_accuracy: 0.5000 - val_loss: 1.0561\n",
      "----------------  Sample: 6 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.5000 - loss: 1.6258 - val_accuracy: 0.5000 - val_loss: 0.8250\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.5000 - loss: 1.1809 - val_accuracy: 0.5000 - val_loss: 0.6470\n",
      "----------------  Sample: 6 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.5000 - loss: 0.8913 - val_accuracy: 0.5200 - val_loss: 0.5082\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.5833 - loss: 0.6778 - val_accuracy: 0.5200 - val_loss: 0.4018\n",
      "----------------  Sample: 6 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.5000 - loss: 0.4427 - val_accuracy: 0.5600 - val_loss: 0.3232\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.5833 - loss: 0.3508 - val_accuracy: 0.5600 - val_loss: 0.2654\n",
      "----------------  Sample: 6 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - accuracy: 0.6667 - loss: 0.3961 - val_accuracy: 0.5800 - val_loss: 0.2221\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.6667 - loss: 0.3085 - val_accuracy: 0.7200 - val_loss: 0.1897\n",
      "----------------  Sample: 6 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.7500 - loss: 0.2625 - val_accuracy: 0.7600 - val_loss: 0.1652\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.7500 - loss: 0.2175 - val_accuracy: 0.7600 - val_loss: 0.1467\n",
      "----------------  Sample: 6 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.5833 - loss: 0.3110 - val_accuracy: 0.8400 - val_loss: 0.1325\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.6667 - loss: 0.2558 - val_accuracy: 0.9000 - val_loss: 0.1214\n",
      "----------------  Sample: 6 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.8333 - loss: 0.1364 - val_accuracy: 0.9200 - val_loss: 0.1131\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.8333 - loss: 0.1235 - val_accuracy: 0.9600 - val_loss: 0.1067\n",
      "----------------  Sample: 6 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.8333 - loss: 0.1491 - val_accuracy: 0.9800 - val_loss: 0.1015\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9167 - loss: 0.1349 - val_accuracy: 1.0000 - val_loss: 0.0971\n",
      "----------------  Sample: 6 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 0.0982 - val_accuracy: 1.0000 - val_loss: 0.0930\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 0.0933 - val_accuracy: 1.0000 - val_loss: 0.0890\n",
      "----------------  Sample: 6 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.9167 - loss: 0.1240 - val_accuracy: 1.0000 - val_loss: 0.0857\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9167 - loss: 0.1149 - val_accuracy: 1.0000 - val_loss: 0.0828\n",
      "----------------  Sample: 6 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step - accuracy: 1.0000 - loss: 0.0721 - val_accuracy: 1.0000 - val_loss: 0.0801\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0653 - val_accuracy: 1.0000 - val_loss: 0.0776\n",
      "----------------  Sample: 6 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 1.0000 - loss: 0.0764 - val_accuracy: 1.0000 - val_loss: 0.0753\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 0.0728 - val_accuracy: 1.0000 - val_loss: 0.0730\n",
      "----------------  Sample: 6 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 1.0000 - loss: 0.0425 - val_accuracy: 0.9800 - val_loss: 0.0709\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.0379 - val_accuracy: 0.9800 - val_loss: 0.0689\n",
      "----------------  Sample: 6 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 1.0000 - loss: 0.0534 - val_accuracy: 0.9800 - val_loss: 0.0670\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 0.0503 - val_accuracy: 0.9800 - val_loss: 0.0651\n",
      "----------------  Sample: 6 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0520 - val_accuracy: 0.9800 - val_loss: 0.0631\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 0.0490 - val_accuracy: 0.9800 - val_loss: 0.0611\n",
      "----------------  Sample: 6 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 1.0000 - loss: 0.0617 - val_accuracy: 0.9800 - val_loss: 0.0589\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 0.0573 - val_accuracy: 0.9800 - val_loss: 0.0567\n",
      "----------------  Sample: 6 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - accuracy: 1.0000 - loss: 0.0499 - val_accuracy: 0.9800 - val_loss: 0.0547\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 0.0471 - val_accuracy: 0.9800 - val_loss: 0.0529\n",
      "----------------  Sample: 6 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - accuracy: 0.9167 - loss: 0.0693 - val_accuracy: 0.9800 - val_loss: 0.0512\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 0.0645 - val_accuracy: 0.9800 - val_loss: 0.0497\n",
      "----------------  Sample: 6 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.9167 - loss: 0.0667 - val_accuracy: 0.9800 - val_loss: 0.0483\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9167 - loss: 0.0627 - val_accuracy: 0.9800 - val_loss: 0.0471\n",
      "----------------  Sample: 6 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 1.0000 - loss: 0.0325 - val_accuracy: 0.9800 - val_loss: 0.0459\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 0.9800 - val_loss: 0.0448\n",
      "----------------  Sample: 6 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.9167 - loss: 0.0513 - val_accuracy: 0.9800 - val_loss: 0.0432\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.9167 - loss: 0.0477 - val_accuracy: 1.0000 - val_loss: 0.0412\n",
      "----------------  Sample: 6 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 1.0000 - loss: 0.0456 - val_accuracy: 1.0000 - val_loss: 0.0391\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0394 - val_accuracy: 1.0000 - val_loss: 0.0370\n",
      "----------------  Sample: 6 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0435 - val_accuracy: 1.0000 - val_loss: 0.0351\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 0.0405 - val_accuracy: 1.0000 - val_loss: 0.0334\n",
      "----------------  Sample: 6 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - accuracy: 1.0000 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 0.0317\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0302\n",
      "----------------  Sample: 6 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 1.0000 - loss: 0.0350 - val_accuracy: 1.0000 - val_loss: 0.0286\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0325 - val_accuracy: 1.0000 - val_loss: 0.0271\n",
      "----------------  Sample: 6 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 0.0334 - val_accuracy: 1.0000 - val_loss: 0.0257\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0308 - val_accuracy: 1.0000 - val_loss: 0.0245\n",
      "----------------  Sample: 6 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 1.0000 - val_loss: 0.0235\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 0.0226\n",
      "----------------  Sample: 6 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 0.0407 - val_accuracy: 1.0000 - val_loss: 0.0218\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 0.0390 - val_accuracy: 1.0000 - val_loss: 0.0211\n",
      "----------------  Sample: 6 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 1.0000 - loss: 0.0361 - val_accuracy: 1.0000 - val_loss: 0.0204\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0330 - val_accuracy: 1.0000 - val_loss: 0.0197\n",
      "----------------  Sample: 6 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 0.0428 - val_accuracy: 1.0000 - val_loss: 0.0188\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 0.0404 - val_accuracy: 1.0000 - val_loss: 0.0178\n",
      "----------------  Sample: 6 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step - accuracy: 1.0000 - loss: 0.0183 - val_accuracy: 1.0000 - val_loss: 0.0169\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 0.0161\n",
      "----------------  Sample: 6 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 1.0000 - loss: 0.0269 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 1.0000 - val_loss: 0.0149\n",
      "----------------  Sample: 6 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 0.0143\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0138\n",
      "----------------  Sample: 6 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0134\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
      "----------------  Sample: 6 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 0.0126\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 1.0000 - val_loss: 0.0123\n",
      "----------------  Sample: 6 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 0.0120\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0116\n",
      "----------------  Sample: 6 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 0.0113\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
      "----------------  Sample: 6 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 1.0000 - val_loss: 0.0107\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0103\n",
      "----------------  Sample: 6 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "----------------  Sample: 6 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0094\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0092\n",
      "----------------  Sample: 6 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0088\n",
      "----------------  Sample: 6 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0086\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
      "----------------  Sample: 6 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0082\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0081\n",
      "----------------  Sample: 6 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
      "----------------  Sample: 6 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0071\n",
      "##### New sample: 7 #####\n",
      "----------------  Sample: 7 | Average: 1  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.5000 - loss: 8.4073 - val_accuracy: 0.5000 - val_loss: 7.1189\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.5000 - loss: 6.5874 - val_accuracy: 0.5000 - val_loss: 6.3260\n",
      "----------------  Sample: 7 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.5000 - loss: 6.0500 - val_accuracy: 0.5000 - val_loss: 5.3433\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.5000 - loss: 4.3073 - val_accuracy: 0.5000 - val_loss: 4.3912\n",
      "----------------  Sample: 7 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step - accuracy: 0.5000 - loss: 4.0164 - val_accuracy: 0.5000 - val_loss: 3.5224\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.5000 - loss: 2.8553 - val_accuracy: 0.5000 - val_loss: 2.8103\n",
      "----------------  Sample: 7 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.5000 - loss: 1.6857 - val_accuracy: 0.5000 - val_loss: 2.2905\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.5000 - loss: 1.1030 - val_accuracy: 0.5000 - val_loss: 1.9091\n",
      "----------------  Sample: 7 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.5000 - loss: 1.4307 - val_accuracy: 0.5000 - val_loss: 1.5989\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.5000 - loss: 1.0473 - val_accuracy: 0.5000 - val_loss: 1.3507\n",
      "----------------  Sample: 7 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.5000 - loss: 1.4961 - val_accuracy: 0.5000 - val_loss: 1.1307\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.5000 - loss: 1.1287 - val_accuracy: 0.5000 - val_loss: 0.9417\n",
      "----------------  Sample: 7 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.5000 - loss: 0.6673 - val_accuracy: 0.5200 - val_loss: 0.7874\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.5000 - loss: 0.4944 - val_accuracy: 0.5200 - val_loss: 0.6640\n",
      "----------------  Sample: 7 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.5000 - loss: 0.8631 - val_accuracy: 0.5200 - val_loss: 0.5582\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.5000 - loss: 0.6725 - val_accuracy: 0.5200 - val_loss: 0.4704\n",
      "----------------  Sample: 7 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.5714 - loss: 0.6722 - val_accuracy: 0.6200 - val_loss: 0.3969\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5714 - loss: 0.5336 - val_accuracy: 0.6800 - val_loss: 0.3380\n",
      "----------------  Sample: 7 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.7143 - loss: 0.2383 - val_accuracy: 0.7000 - val_loss: 0.2926\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.7143 - loss: 0.2004 - val_accuracy: 0.7000 - val_loss: 0.2575\n",
      "----------------  Sample: 7 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.6429 - loss: 0.1859 - val_accuracy: 0.7200 - val_loss: 0.2300\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6429 - loss: 0.1625 - val_accuracy: 0.7600 - val_loss: 0.2079\n",
      "----------------  Sample: 7 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.7857 - loss: 0.2647 - val_accuracy: 0.8000 - val_loss: 0.1875\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.7857 - loss: 0.2260 - val_accuracy: 0.8200 - val_loss: 0.1693\n",
      "----------------  Sample: 7 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step - accuracy: 0.8571 - loss: 0.1482 - val_accuracy: 0.8200 - val_loss: 0.1543\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.8571 - loss: 0.1311 - val_accuracy: 0.8200 - val_loss: 0.1420\n",
      "----------------  Sample: 7 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - accuracy: 0.9286 - loss: 0.1268 - val_accuracy: 0.8400 - val_loss: 0.1315\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9286 - loss: 0.1087 - val_accuracy: 0.8600 - val_loss: 0.1226\n",
      "----------------  Sample: 7 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.9286 - loss: 0.0911 - val_accuracy: 0.8600 - val_loss: 0.1158\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9286 - loss: 0.0850 - val_accuracy: 0.8600 - val_loss: 0.1105\n",
      "----------------  Sample: 7 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - accuracy: 0.9286 - loss: 0.0959 - val_accuracy: 0.9000 - val_loss: 0.1063\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.9286 - loss: 0.0897 - val_accuracy: 0.9000 - val_loss: 0.1026\n",
      "----------------  Sample: 7 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.9286 - loss: 0.1285 - val_accuracy: 0.9200 - val_loss: 0.0990\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.9286 - loss: 0.1197 - val_accuracy: 0.9400 - val_loss: 0.0955\n",
      "----------------  Sample: 7 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9286 - loss: 0.0879 - val_accuracy: 0.9400 - val_loss: 0.0922\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9286 - loss: 0.0800 - val_accuracy: 0.9800 - val_loss: 0.0891\n",
      "----------------  Sample: 7 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9800 - val_loss: 0.0863\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 0.0512 - val_accuracy: 0.9800 - val_loss: 0.0836\n",
      "----------------  Sample: 7 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step - accuracy: 1.0000 - loss: 0.0920 - val_accuracy: 0.9800 - val_loss: 0.0809\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0859 - val_accuracy: 0.9800 - val_loss: 0.0781\n",
      "----------------  Sample: 7 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.9286 - loss: 0.0758 - val_accuracy: 0.9800 - val_loss: 0.0754\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9286 - loss: 0.0704 - val_accuracy: 0.9800 - val_loss: 0.0729\n",
      "----------------  Sample: 7 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 0.0445 - val_accuracy: 0.9800 - val_loss: 0.0708\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 0.0408 - val_accuracy: 0.9800 - val_loss: 0.0688\n",
      "----------------  Sample: 7 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 0.0636 - val_accuracy: 0.9800 - val_loss: 0.0669\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.0590 - val_accuracy: 0.9800 - val_loss: 0.0650\n",
      "----------------  Sample: 7 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 0.0459 - val_accuracy: 0.9800 - val_loss: 0.0635\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 0.0419 - val_accuracy: 0.9800 - val_loss: 0.0621\n",
      "----------------  Sample: 7 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.9286 - loss: 0.0877 - val_accuracy: 0.9800 - val_loss: 0.0602\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9286 - loss: 0.0829 - val_accuracy: 0.9800 - val_loss: 0.0578\n",
      "----------------  Sample: 7 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step - accuracy: 1.0000 - loss: 0.0406 - val_accuracy: 0.9800 - val_loss: 0.0553\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 1.0000 - loss: 0.0385 - val_accuracy: 1.0000 - val_loss: 0.0529\n",
      "----------------  Sample: 7 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 0.0715 - val_accuracy: 1.0000 - val_loss: 0.0503\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 0.0661 - val_accuracy: 1.0000 - val_loss: 0.0479\n",
      "----------------  Sample: 7 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 0.0455\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0285 - val_accuracy: 1.0000 - val_loss: 0.0432\n",
      "----------------  Sample: 7 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 1.0000 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0410\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0391\n",
      "----------------  Sample: 7 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 0.0248 - val_accuracy: 1.0000 - val_loss: 0.0373\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0229 - val_accuracy: 1.0000 - val_loss: 0.0356\n",
      "----------------  Sample: 7 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step - accuracy: 1.0000 - loss: 0.0292 - val_accuracy: 1.0000 - val_loss: 0.0339\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
      "----------------  Sample: 7 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0453 - val_accuracy: 1.0000 - val_loss: 0.0306\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.0432 - val_accuracy: 1.0000 - val_loss: 0.0293\n",
      "----------------  Sample: 7 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 0.0280\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 1.0000 - val_loss: 0.0268\n",
      "----------------  Sample: 7 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 1.0000 - loss: 0.0473 - val_accuracy: 1.0000 - val_loss: 0.0257\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 0.0451 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
      "----------------  Sample: 7 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 1.0000 - val_loss: 0.0238\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 0.0230\n",
      "----------------  Sample: 7 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0222\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0216\n",
      "----------------  Sample: 7 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0210\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0204\n",
      "----------------  Sample: 7 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0199\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0193\n",
      "----------------  Sample: 7 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0188\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 0.0184\n",
      "----------------  Sample: 7 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0179\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0175\n",
      "----------------  Sample: 7 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 0.0169\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 1.0000 - val_loss: 0.0164\n",
      "----------------  Sample: 7 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0159\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0154\n",
      "----------------  Sample: 7 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0149\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0144\n",
      "----------------  Sample: 7 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 1.0000 - val_loss: 0.0135\n",
      "----------------  Sample: 7 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0132\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0129\n",
      "----------------  Sample: 7 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0126\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 1.0000 - val_loss: 0.0123\n",
      "----------------  Sample: 7 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0120\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0118\n",
      "----------------  Sample: 7 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0113\n",
      "----------------  Sample: 7 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 0.0198 - val_accuracy: 1.0000 - val_loss: 0.0110\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0107\n",
      "----------------  Sample: 7 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 1.0000 - loss: 0.0330 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 0.0312 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
      "##### New sample: 8 #####\n",
      "----------------  Sample: 8 | Average: 1  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.5000 - loss: 8.5636 - val_accuracy: 0.5000 - val_loss: 7.1073\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.5000 - loss: 6.9012 - val_accuracy: 0.5000 - val_loss: 6.2783\n",
      "----------------  Sample: 8 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step - accuracy: 0.5000 - loss: 5.3739 - val_accuracy: 0.5000 - val_loss: 5.3002\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.5000 - loss: 3.9565 - val_accuracy: 0.5000 - val_loss: 4.3612\n",
      "----------------  Sample: 8 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.5000 - loss: 4.8825 - val_accuracy: 0.5000 - val_loss: 3.4675\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.5000 - loss: 3.4004 - val_accuracy: 0.5000 - val_loss: 2.7122\n",
      "----------------  Sample: 8 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - accuracy: 0.5000 - loss: 3.0478 - val_accuracy: 0.5000 - val_loss: 2.0810\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.5000 - loss: 2.1810 - val_accuracy: 0.5000 - val_loss: 1.5954\n",
      "----------------  Sample: 8 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.5000 - loss: 0.9742 - val_accuracy: 0.5000 - val_loss: 1.2476\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.5000 - loss: 0.6606 - val_accuracy: 0.5000 - val_loss: 0.9944\n",
      "----------------  Sample: 8 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - accuracy: 0.5000 - loss: 1.0055 - val_accuracy: 0.5000 - val_loss: 0.7943\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.5000 - loss: 0.7685 - val_accuracy: 0.5200 - val_loss: 0.6401\n",
      "----------------  Sample: 8 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.5625 - loss: 0.6370 - val_accuracy: 0.5400 - val_loss: 0.5262\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.6250 - loss: 0.4844 - val_accuracy: 0.5400 - val_loss: 0.4409\n",
      "----------------  Sample: 8 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.6250 - loss: 0.2447 - val_accuracy: 0.5800 - val_loss: 0.3783\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6875 - loss: 0.2060 - val_accuracy: 0.6000 - val_loss: 0.3317\n",
      "----------------  Sample: 8 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.5625 - loss: 0.3473 - val_accuracy: 0.6200 - val_loss: 0.2950\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6250 - loss: 0.2828 - val_accuracy: 0.6600 - val_loss: 0.2657\n",
      "----------------  Sample: 8 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - accuracy: 0.6875 - loss: 0.2459 - val_accuracy: 0.8000 - val_loss: 0.2416\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.7500 - loss: 0.2063 - val_accuracy: 0.8200 - val_loss: 0.2209\n",
      "----------------  Sample: 8 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step - accuracy: 0.8125 - loss: 0.2608 - val_accuracy: 0.8600 - val_loss: 0.2002\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.8125 - loss: 0.2236 - val_accuracy: 0.8800 - val_loss: 0.1809\n",
      "----------------  Sample: 8 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 0.0987 - val_accuracy: 0.8800 - val_loss: 0.1653\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 1.0000 - loss: 0.0926 - val_accuracy: 0.8800 - val_loss: 0.1522\n",
      "----------------  Sample: 8 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.9375 - loss: 0.0945 - val_accuracy: 0.9000 - val_loss: 0.1410\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.9375 - loss: 0.0834 - val_accuracy: 0.9200 - val_loss: 0.1316\n",
      "----------------  Sample: 8 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step - accuracy: 0.9375 - loss: 0.0846 - val_accuracy: 0.9200 - val_loss: 0.1239\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9375 - loss: 0.0770 - val_accuracy: 0.9400 - val_loss: 0.1174\n",
      "----------------  Sample: 8 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 1.0000 - loss: 0.0546 - val_accuracy: 0.9400 - val_loss: 0.1119\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 0.0511 - val_accuracy: 0.9200 - val_loss: 0.1071\n",
      "----------------  Sample: 8 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.8750 - loss: 0.0943 - val_accuracy: 0.9400 - val_loss: 0.1026\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.9375 - loss: 0.0898 - val_accuracy: 0.9400 - val_loss: 0.0982\n",
      "----------------  Sample: 8 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.9375 - loss: 0.1035 - val_accuracy: 0.9400 - val_loss: 0.0931\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9375 - loss: 0.0939 - val_accuracy: 0.9400 - val_loss: 0.0877\n",
      "----------------  Sample: 8 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8750 - loss: 0.1864 - val_accuracy: 0.9200 - val_loss: 0.0821\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8750 - loss: 0.1669 - val_accuracy: 0.9200 - val_loss: 0.0769\n",
      "----------------  Sample: 8 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0444 - val_accuracy: 0.9200 - val_loss: 0.0726\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.0413 - val_accuracy: 0.9400 - val_loss: 0.0692\n",
      "----------------  Sample: 8 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 1.0000 - loss: 0.0856 - val_accuracy: 0.9600 - val_loss: 0.0660\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0814 - val_accuracy: 0.9600 - val_loss: 0.0630\n",
      "----------------  Sample: 8 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.8750 - loss: 0.0933 - val_accuracy: 0.9800 - val_loss: 0.0600\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9375 - loss: 0.0824 - val_accuracy: 0.9800 - val_loss: 0.0570\n",
      "----------------  Sample: 8 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 0.0596 - val_accuracy: 0.9800 - val_loss: 0.0541\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 0.0564 - val_accuracy: 0.9800 - val_loss: 0.0515\n",
      "----------------  Sample: 8 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - accuracy: 1.0000 - loss: 0.0394 - val_accuracy: 0.9800 - val_loss: 0.0492\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 0.0361 - val_accuracy: 0.9800 - val_loss: 0.0472\n",
      "----------------  Sample: 8 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step - accuracy: 1.0000 - loss: 0.0542 - val_accuracy: 0.9800 - val_loss: 0.0453\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0503 - val_accuracy: 0.9800 - val_loss: 0.0435\n",
      "----------------  Sample: 8 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0832 - val_accuracy: 0.9800 - val_loss: 0.0417\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 0.0763 - val_accuracy: 0.9800 - val_loss: 0.0398\n",
      "----------------  Sample: 8 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0376 - val_accuracy: 0.9800 - val_loss: 0.0381\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 0.9800 - val_loss: 0.0367\n",
      "----------------  Sample: 8 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 1.0000 - loss: 0.0213 - val_accuracy: 0.9800 - val_loss: 0.0355\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.9800 - val_loss: 0.0345\n",
      "----------------  Sample: 8 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 1.0000 - loss: 0.0314 - val_accuracy: 0.9800 - val_loss: 0.0334\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: 0.0297 - val_accuracy: 0.9800 - val_loss: 0.0324\n",
      "----------------  Sample: 8 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.9800 - val_loss: 0.0315\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.9800 - val_loss: 0.0306\n",
      "----------------  Sample: 8 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.9375 - loss: 0.0375 - val_accuracy: 0.9800 - val_loss: 0.0294\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9375 - loss: 0.0353 - val_accuracy: 1.0000 - val_loss: 0.0280\n",
      "----------------  Sample: 8 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0267\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 1.0000 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0256\n",
      "----------------  Sample: 8 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0246\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0237\n",
      "----------------  Sample: 8 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0279 - val_accuracy: 1.0000 - val_loss: 0.0230\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0223\n",
      "----------------  Sample: 8 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 1.0000 - val_loss: 0.0211\n",
      "----------------  Sample: 8 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.0205\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 1.0000 - loss: 0.0210 - val_accuracy: 1.0000 - val_loss: 0.0198\n",
      "----------------  Sample: 8 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 1.0000 - val_loss: 0.0192\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0187\n",
      "----------------  Sample: 8 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0181\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0176\n",
      "----------------  Sample: 8 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0172\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 1.0000 - val_loss: 0.0168\n",
      "----------------  Sample: 8 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0165\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0162\n",
      "----------------  Sample: 8 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0159\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 0.0155\n",
      "----------------  Sample: 8 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0150\n",
      "----------------  Sample: 8 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0147\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0145\n",
      "----------------  Sample: 8 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 0.0142\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
      "----------------  Sample: 8 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 1.0000 - loss: 0.0168 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
      "----------------  Sample: 8 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 0.0129\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0125\n",
      "----------------  Sample: 8 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0122\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 0.0119\n",
      "----------------  Sample: 8 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0116\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0113\n",
      "----------------  Sample: 8 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
      "----------------  Sample: 8 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0106\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
      "----------------  Sample: 8 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "##### New sample: 9 #####\n",
      "----------------  Sample: 9 | Average: 1  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5000 - loss: 7.8108 - val_accuracy: 0.5000 - val_loss: 7.0672\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5000 - loss: 6.2972 - val_accuracy: 0.5000 - val_loss: 6.1998\n",
      "----------------  Sample: 9 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.5000 - loss: 6.4995 - val_accuracy: 0.5000 - val_loss: 5.0749\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.5000 - loss: 4.7977 - val_accuracy: 0.5000 - val_loss: 3.9834\n",
      "----------------  Sample: 9 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.5000 - loss: 3.4436 - val_accuracy: 0.5000 - val_loss: 3.1092\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.5000 - loss: 2.3665 - val_accuracy: 0.5000 - val_loss: 2.4454\n",
      "----------------  Sample: 9 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 0.5000 - loss: 2.8511 - val_accuracy: 0.5000 - val_loss: 1.9021\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.5000 - loss: 1.9973 - val_accuracy: 0.5000 - val_loss: 1.4703\n",
      "----------------  Sample: 9 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.5000 - loss: 2.0263 - val_accuracy: 0.5000 - val_loss: 1.1184\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.5000 - loss: 1.4597 - val_accuracy: 0.5000 - val_loss: 0.8466\n",
      "----------------  Sample: 9 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.5000 - loss: 1.0634 - val_accuracy: 0.5000 - val_loss: 0.6433\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.5000 - loss: 0.7764 - val_accuracy: 0.5200 - val_loss: 0.4937\n",
      "----------------  Sample: 9 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.5000 - loss: 0.6551 - val_accuracy: 0.5200 - val_loss: 0.3877\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.5000 - loss: 0.4943 - val_accuracy: 0.5600 - val_loss: 0.3141\n",
      "----------------  Sample: 9 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.5000 - loss: 0.2834 - val_accuracy: 0.6400 - val_loss: 0.2626\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.5556 - loss: 0.2306 - val_accuracy: 0.7000 - val_loss: 0.2255\n",
      "----------------  Sample: 9 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step - accuracy: 0.7778 - loss: 0.2963 - val_accuracy: 0.7400 - val_loss: 0.1959\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.7778 - loss: 0.2406 - val_accuracy: 0.7600 - val_loss: 0.1719\n",
      "----------------  Sample: 9 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.8889 - loss: 0.1219 - val_accuracy: 0.7800 - val_loss: 0.1535\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.8889 - loss: 0.1108 - val_accuracy: 0.8600 - val_loss: 0.1389\n",
      "----------------  Sample: 9 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - accuracy: 0.9444 - loss: 0.1365 - val_accuracy: 0.8800 - val_loss: 0.1275\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9444 - loss: 0.1177 - val_accuracy: 0.8800 - val_loss: 0.1182\n",
      "----------------  Sample: 9 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.9444 - loss: 0.1088 - val_accuracy: 0.9000 - val_loss: 0.1108\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 0.0957 - val_accuracy: 0.9200 - val_loss: 0.1050\n",
      "----------------  Sample: 9 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step - accuracy: 0.9444 - loss: 0.1006 - val_accuracy: 0.9600 - val_loss: 0.0997\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0922 - val_accuracy: 0.9800 - val_loss: 0.0947\n",
      "----------------  Sample: 9 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 1.0000 - loss: 0.0674 - val_accuracy: 0.9800 - val_loss: 0.0904\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0638 - val_accuracy: 0.9800 - val_loss: 0.0868\n",
      "----------------  Sample: 9 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.9444 - loss: 0.0940 - val_accuracy: 0.9800 - val_loss: 0.0831\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9444 - loss: 0.0894 - val_accuracy: 0.9800 - val_loss: 0.0795\n",
      "----------------  Sample: 9 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step - accuracy: 1.0000 - loss: 0.0626 - val_accuracy: 0.9800 - val_loss: 0.0760\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0583 - val_accuracy: 0.9800 - val_loss: 0.0729\n",
      "----------------  Sample: 9 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 0.0577 - val_accuracy: 0.9800 - val_loss: 0.0698\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 0.0545 - val_accuracy: 0.9800 - val_loss: 0.0667\n",
      "----------------  Sample: 9 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 1.0000 - loss: 0.0627 - val_accuracy: 0.9800 - val_loss: 0.0633\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 0.0581 - val_accuracy: 0.9800 - val_loss: 0.0600\n",
      "----------------  Sample: 9 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 1.0000 - loss: 0.0550 - val_accuracy: 0.9800 - val_loss: 0.0565\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.0496 - val_accuracy: 0.9800 - val_loss: 0.0531\n",
      "----------------  Sample: 9 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 1.0000 - loss: 0.0564 - val_accuracy: 0.9800 - val_loss: 0.0501\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 1.0000 - loss: 0.0543 - val_accuracy: 0.9800 - val_loss: 0.0476\n",
      "----------------  Sample: 9 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0502 - val_accuracy: 0.9800 - val_loss: 0.0453\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 1.0000 - loss: 0.0470 - val_accuracy: 0.9800 - val_loss: 0.0433\n",
      "----------------  Sample: 9 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - accuracy: 1.0000 - loss: 0.0395 - val_accuracy: 0.9800 - val_loss: 0.0414\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0365 - val_accuracy: 0.9800 - val_loss: 0.0396\n",
      "----------------  Sample: 9 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.9800 - val_loss: 0.0379\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.9800 - val_loss: 0.0364\n",
      "----------------  Sample: 9 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 1.0000 - loss: 0.0528 - val_accuracy: 0.9800 - val_loss: 0.0351\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 1.0000 - loss: 0.0496 - val_accuracy: 0.9800 - val_loss: 0.0338\n",
      "----------------  Sample: 9 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 0.0381 - val_accuracy: 0.9800 - val_loss: 0.0327\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 0.9800 - val_loss: 0.0317\n",
      "----------------  Sample: 9 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 1.0000 - loss: 0.0290 - val_accuracy: 0.9800 - val_loss: 0.0308\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.9800 - val_loss: 0.0300\n",
      "----------------  Sample: 9 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.9800 - val_loss: 0.0292\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 0.9800 - val_loss: 0.0285\n",
      "----------------  Sample: 9 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 0.9800 - val_loss: 0.0278\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.9800 - val_loss: 0.0271\n",
      "----------------  Sample: 9 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8889 - loss: 0.0531 - val_accuracy: 0.9800 - val_loss: 0.0262\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.8889 - loss: 0.0507 - val_accuracy: 1.0000 - val_loss: 0.0252\n",
      "----------------  Sample: 9 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 1.0000 - loss: 0.0344 - val_accuracy: 1.0000 - val_loss: 0.0240\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 0.0322 - val_accuracy: 1.0000 - val_loss: 0.0227\n",
      "----------------  Sample: 9 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0216\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.0205\n",
      "----------------  Sample: 9 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 1.0000 - loss: 0.0286 - val_accuracy: 1.0000 - val_loss: 0.0196\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 0.0266 - val_accuracy: 1.0000 - val_loss: 0.0188\n",
      "----------------  Sample: 9 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 0.0299 - val_accuracy: 1.0000 - val_loss: 0.0180\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 0.0172\n",
      "----------------  Sample: 9 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0164\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0158\n",
      "----------------  Sample: 9 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0147\n",
      "----------------  Sample: 9 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 0.0142\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0139\n",
      "----------------  Sample: 9 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 0.0135\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
      "----------------  Sample: 9 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 1.0000 - val_loss: 0.0127\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0123\n",
      "----------------  Sample: 9 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 1.0000 - val_loss: 0.0120\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0117\n",
      "----------------  Sample: 9 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0114\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
      "----------------  Sample: 9 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 0.0105\n",
      "----------------  Sample: 9 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 0.0100\n",
      "----------------  Sample: 9 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0093\n",
      "----------------  Sample: 9 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0087\n",
      "----------------  Sample: 9 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 0.0083\n",
      "----------------  Sample: 9 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0081\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0079\n",
      "----------------  Sample: 9 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0077\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0075\n",
      "----------------  Sample: 9 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0073\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
      "----------------  Sample: 9 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0070\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
      "----------------  Sample: 9 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
      "##### New sample: 10 #####\n",
      "----------------  Sample: 10 | Average: 1  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.5000 - loss: 7.9468 - val_accuracy: 0.5000 - val_loss: 7.0426\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.5000 - loss: 6.5031 - val_accuracy: 0.5000 - val_loss: 6.1319\n",
      "----------------  Sample: 10 | Average: 2  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.5000 - loss: 5.8384 - val_accuracy: 0.5000 - val_loss: 5.0973\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.5000 - loss: 4.3452 - val_accuracy: 0.5000 - val_loss: 4.1311\n",
      "----------------  Sample: 10 | Average: 3  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.5000 - loss: 4.7622 - val_accuracy: 0.5000 - val_loss: 3.2032\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.5000 - loss: 3.4229 - val_accuracy: 0.5000 - val_loss: 2.4377\n",
      "----------------  Sample: 10 | Average: 4  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step - accuracy: 0.5000 - loss: 2.8537 - val_accuracy: 0.5000 - val_loss: 1.8553\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.5000 - loss: 2.0440 - val_accuracy: 0.5000 - val_loss: 1.4256\n",
      "----------------  Sample: 10 | Average: 5  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.5000 - loss: 1.2347 - val_accuracy: 0.5000 - val_loss: 1.1161\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.5000 - loss: 0.8873 - val_accuracy: 0.5000 - val_loss: 0.8945\n",
      "----------------  Sample: 10 | Average: 6  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.5000 - loss: 1.2694 - val_accuracy: 0.5200 - val_loss: 0.7110\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.5000 - loss: 0.9569 - val_accuracy: 0.5400 - val_loss: 0.5620\n",
      "----------------  Sample: 10 | Average: 7  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step - accuracy: 0.5000 - loss: 0.3485 - val_accuracy: 0.5600 - val_loss: 0.4540\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.5500 - loss: 0.2782 - val_accuracy: 0.5800 - val_loss: 0.3751\n",
      "----------------  Sample: 10 | Average: 8  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - accuracy: 0.5000 - loss: 0.3883 - val_accuracy: 0.6000 - val_loss: 0.3103\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.5500 - loss: 0.3120 - val_accuracy: 0.6400 - val_loss: 0.2565\n",
      "----------------  Sample: 10 | Average: 9  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.6000 - loss: 0.2014 - val_accuracy: 0.6800 - val_loss: 0.2156\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.7000 - loss: 0.1736 - val_accuracy: 0.7800 - val_loss: 0.1844\n",
      "----------------  Sample: 10 | Average: 10  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.9000 - loss: 0.1520 - val_accuracy: 0.7800 - val_loss: 0.1603\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.9000 - loss: 0.1257 - val_accuracy: 0.8600 - val_loss: 0.1420\n",
      "----------------  Sample: 10 | Average: 11  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.9500 - loss: 0.1337 - val_accuracy: 0.9000 - val_loss: 0.1289\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.9500 - loss: 0.1193 - val_accuracy: 0.9200 - val_loss: 0.1196\n",
      "----------------  Sample: 10 | Average: 12  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 1.0000 - loss: 0.1081 - val_accuracy: 0.9400 - val_loss: 0.1124\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.0989 - val_accuracy: 0.9400 - val_loss: 0.1065\n",
      "----------------  Sample: 10 | Average: 13  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.9000 - loss: 0.1239 - val_accuracy: 0.9200 - val_loss: 0.1017\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9500 - loss: 0.1174 - val_accuracy: 0.9200 - val_loss: 0.0976\n",
      "----------------  Sample: 10 | Average: 14  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.0732 - val_accuracy: 0.9200 - val_loss: 0.0939\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0674 - val_accuracy: 0.9400 - val_loss: 0.0905\n",
      "----------------  Sample: 10 | Average: 15  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9000 - loss: 0.1015 - val_accuracy: 0.9400 - val_loss: 0.0869\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0928 - val_accuracy: 0.9400 - val_loss: 0.0832\n",
      "----------------  Sample: 10 | Average: 16  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.9500 - loss: 0.1202 - val_accuracy: 0.9400 - val_loss: 0.0791\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9500 - loss: 0.1128 - val_accuracy: 0.9400 - val_loss: 0.0744\n",
      "----------------  Sample: 10 | Average: 17  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9500 - loss: 0.0788 - val_accuracy: 0.9600 - val_loss: 0.0697\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9500 - loss: 0.0713 - val_accuracy: 0.9800 - val_loss: 0.0650\n",
      "----------------  Sample: 10 | Average: 18  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.9500 - loss: 0.0810 - val_accuracy: 0.9800 - val_loss: 0.0604\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9500 - loss: 0.0763 - val_accuracy: 0.9800 - val_loss: 0.0559\n",
      "----------------  Sample: 10 | Average: 19  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.9500 - loss: 0.0609 - val_accuracy: 1.0000 - val_loss: 0.0519\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 0.0558 - val_accuracy: 1.0000 - val_loss: 0.0482\n",
      "----------------  Sample: 10 | Average: 20  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - accuracy: 0.9500 - loss: 0.0597 - val_accuracy: 1.0000 - val_loss: 0.0448\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9500 - loss: 0.0549 - val_accuracy: 1.0000 - val_loss: 0.0416\n",
      "----------------  Sample: 10 | Average: 21  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step - accuracy: 1.0000 - loss: 0.0464 - val_accuracy: 1.0000 - val_loss: 0.0387\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 0.0432 - val_accuracy: 1.0000 - val_loss: 0.0362\n",
      "----------------  Sample: 10 | Average: 22  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 1.0000 - loss: 0.0455 - val_accuracy: 1.0000 - val_loss: 0.0337\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0424 - val_accuracy: 1.0000 - val_loss: 0.0315\n",
      "----------------  Sample: 10 | Average: 23  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.0471 - val_accuracy: 1.0000 - val_loss: 0.0295\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 1.0000 - loss: 0.0425 - val_accuracy: 1.0000 - val_loss: 0.0277\n",
      "----------------  Sample: 10 | Average: 24  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 1.0000 - loss: 0.0377 - val_accuracy: 1.0000 - val_loss: 0.0262\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.0354 - val_accuracy: 1.0000 - val_loss: 0.0249\n",
      "----------------  Sample: 10 | Average: 25  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step - accuracy: 1.0000 - loss: 0.0268 - val_accuracy: 1.0000 - val_loss: 0.0238\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 1.0000 - val_loss: 0.0229\n",
      "----------------  Sample: 10 | Average: 26  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 1.0000 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 0.0221\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 0.0251 - val_accuracy: 1.0000 - val_loss: 0.0214\n",
      "----------------  Sample: 10 | Average: 27  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step - accuracy: 1.0000 - loss: 0.0263 - val_accuracy: 1.0000 - val_loss: 0.0207\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0201\n",
      "----------------  Sample: 10 | Average: 28  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 1.0000 - loss: 0.0266 - val_accuracy: 1.0000 - val_loss: 0.0195\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0189\n",
      "----------------  Sample: 10 | Average: 29  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0268 - val_accuracy: 1.0000 - val_loss: 0.0184\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0255 - val_accuracy: 1.0000 - val_loss: 0.0179\n",
      "----------------  Sample: 10 | Average: 30  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.0174\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0170\n",
      "----------------  Sample: 10 | Average: 31  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0165\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 1.0000 - val_loss: 0.0160\n",
      "----------------  Sample: 10 | Average: 32  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 0.0156\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 0.0152\n",
      "----------------  Sample: 10 | Average: 33  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0148\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0144\n",
      "----------------  Sample: 10 | Average: 34  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
      "----------------  Sample: 10 | Average: 35  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
      "----------------  Sample: 10 | Average: 36  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0125\n",
      "----------------  Sample: 10 | Average: 37  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 1.0000 - val_loss: 0.0122\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 1.0000 - val_loss: 0.0120\n",
      "----------------  Sample: 10 | Average: 38  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0117\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
      "----------------  Sample: 10 | Average: 39  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0113\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
      "----------------  Sample: 10 | Average: 40  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0109\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 0.0107\n",
      "----------------  Sample: 10 | Average: 41  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0106\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
      "----------------  Sample: 10 | Average: 42  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
      "----------------  Sample: 10 | Average: 43  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 0.0099\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0098\n",
      "----------------  Sample: 10 | Average: 44  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0094\n",
      "----------------  Sample: 10 | Average: 45  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0092\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "----------------  Sample: 10 | Average: 46  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0088\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0086\n",
      "----------------  Sample: 10 | Average: 47  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0082\n",
      "----------------  Sample: 10 | Average: 48  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
      "----------------  Sample: 10 | Average: 49  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 1.0000 - val_loss: 0.0077\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
      "----------------  Sample: 10 | Average: 50  ----------------\n",
      "Epoch 1/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
      "Epoch 2/2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0073\n"
     ]
    }
   ],
   "source": [
    "# Create result list whose 8 columns are:\n",
    "# train loss (mean, std), test loss (mean, std), train acc (mean, std), test acc (mean, std)\n",
    "results_raw = np.zeros((50, 10, 4))\n",
    "results = np.zeros((10, 8))\n",
    "\n",
    "# Create testing data\n",
    "x_test = np.zeros((50, 2, N))\n",
    "y_test = np.zeros(50)\n",
    "for i in range(0, 25):\n",
    "    # Test data\n",
    "    x_test[i, :, :] = data[\"forr_f\"][i+25, :, :]\n",
    "    y_test[i] = 1\n",
    "    x_test[i+25, :, :] = data[\"rand_f\"][i+25, :, :]\n",
    "    y_test[i+25] = 0\n",
    "\n",
    "# Create training data + averages\n",
    "n_samples, n_avg = data_idx.shape\n",
    "for i in range(n_samples):\n",
    "    print(\"##### New sample: \" + str(i+1) + \" #####\")\n",
    "    # Load initial weights\n",
    "    model.load_weights('model.weights.h5')\n",
    "    for j in range(n_avg):\n",
    "        print(\"----------------  Sample: \" + str(i+1) + \" | Average: \" + str(j+1) + \"  ----------------\")\n",
    "        # Training data\n",
    "        x_train = np.zeros(((i+1)*2, 2, N))\n",
    "        y_train = np.zeros((i+1)*2)\n",
    "        tmp_idx = ast.literal_eval(data_idx[i, j])\n",
    "        for k in range(len(tmp_idx)):\n",
    "            x_train[k, :, :] = data[\"forr_f\"][tmp_idx[k], :, :]\n",
    "            y_train[k] = 1\n",
    "            x_train[k+(i+1), :, :] = data[\"rand_f\"][tmp_idx[k], :, :]\n",
    "            y_train[k+(i+1)] = 0\n",
    "        # Reshape the data to fit the network input (samples, vector)\n",
    "        x_train_1 = x_train[:, 0].reshape(-1, N)\n",
    "        x_train_2 = x_train[:, 1].reshape(-1, N)\n",
    "        x_test_1 = x_test[:, 0].reshape(-1, N)\n",
    "        x_test_2 = x_test[:, 1].reshape(-1, N)\n",
    "\n",
    "        # Train the model and store the history into results_raw\n",
    "        history = model.fit([x_train_1, x_train_2], y_train, batch_size=128, epochs=2, validation_data=([x_test_1, x_test_2], y_test))\n",
    "        results_raw[j, i, :] = [history.history['loss'][-1], history.history['val_loss'][-1], history.history['accuracy'][-1], history.history['val_accuracy'][-1]]\n",
    "        del history\n",
    "\n",
    "# Calculate the averages and standard deviations\n",
    "for i in range(10):\n",
    "    results[i, 0::2] = np.mean(results_raw[:, i, :], axis=0)\n",
    "    results[i, 1::2] = np.std(results_raw[:, i, :], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 2.5))\n",
    "# plt.errorbar(np.arange(1, 11), results[:, 0], yerr=results[:, 1], label='Train loss')\n",
    "# plt.errorbar(np.arange(1, 11), results[:, 2], yerr=results[:, 3], label='Test loss')\n",
    "\n",
    "# Calculate the upper errors\n",
    "upper_train_error = np.minimum(results[:, 5], 1 - results[:, 4])\n",
    "upper_test_error = np.minimum(results[:, 7], 1 - results[:, 6])\n",
    "plt.errorbar(np.arange(1, 11), results[:, 4], yerr=[results[:, 5], upper_train_error], label='Train accuracy')\n",
    "plt.errorbar(np.arange(1, 11), results[:, 6], yerr=[results[:, 7], upper_test_error], label='Test accuracy')\n",
    "\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim(0.9, 1)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results for classical vs quantum comparision plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result to npz\n",
    "# np.savez('../data/forr_siamese_nn_n4.npz', results=results)\n",
    "# np.savez('../data/forr_siamese_nn_n6.npz', results=results)\n",
    "np.savez('../data/forr_siamese_nn_n8.npz', results=results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
